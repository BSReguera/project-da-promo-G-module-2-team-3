{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_10684\\253687804.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from selenium import webdriver  \n",
    "from webdriver_manager.chrome import ChromeDriverManager  \n",
    "from selenium.webdriver.common.keys import Keys  \n",
    "from selenium.webdriver.support.ui import Select \n",
    "\n",
    "from time import sleep\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CÓDIGO ROTTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda = # lista de listas con películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_notas = []\n",
    "errores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.google.com/')\n",
    "driver.maximize_window()\n",
    "sleep(2)\n",
    "\n",
    "driver.find_element('css selector', '#W0wltc > div').click()\n",
    "sleep(1)\n",
    "\n",
    "\n",
    "for pelicula in busqueda:\n",
    "    notas = [f'{pelicula[0]}',]\n",
    "        \n",
    "    try:\n",
    "        driver.find_element('css selector', '#APjFqb').send_keys(pelicula[2],' ', pelicula[4], ' rotten tomatoes', Keys.ENTER)\n",
    "        sleep(1)\n",
    "\n",
    "        nota = driver.find_element('css selector', '#rso > div:nth-child(1) > div > div > div:nth-child(3) > div > span:nth-child(2)').text\n",
    "        \n",
    "    except:\n",
    "        errores.append(pelicula)\n",
    "        \n",
    "    notas.append(nota[-3:])    \n",
    "    driver.find_element('css selector', '#APjFqb').clear() \n",
    "    \n",
    "    lista_notas.append(tuple(notas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lista_notas\n",
    "df.to_csv('NotasRotten.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CÓDIGO IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_por_peli = []\n",
    "fallos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llegar a web:\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.imdb.com/')\n",
    "driver.maximize_window()\n",
    "sleep(random.randint(1,3))\n",
    "\n",
    "\n",
    "# rechazar cookies\n",
    "driver.find_element('css selector', '#__next > div > div > div.sc-jrcTuL.bPmWiM > div > button.icb-btn.sc-bcXHqe.sc-hLBbgP.sc-ftTHYK.dcvrLS.dufgkr.ecppKW').click()\n",
    "sleep(random.randint(1,3))\n",
    "\n",
    "contador = 0\n",
    "\n",
    "# entrando en cada título\n",
    "for peli in busqueda:\n",
    "    lista_info = [f'{peli[0]}',]\n",
    "    contador +=1\n",
    "    print(f'Película: {contador}')\n",
    "\n",
    "    try:\n",
    "        \n",
    "        # metemos el ID en el buscador\n",
    "        try:\n",
    "            driver.find_element('css selector', '#suggestion-search').send_keys(peli[0], Keys.ENTER)\n",
    "            sleep(random.randint(1,3))\n",
    "\n",
    "            # extraemos info\n",
    "            info = driver.find_element('xpath' , f'//*[@id=\"__next\"]/main/div/section[1]/section/div[3]/section').text\n",
    "            lista_info.append(info.split('\\n'))\n",
    "\n",
    "            info_por_peli.append(lista_info)\n",
    "        except:\n",
    "            fallos.append(peli)\n",
    "            driver.find_element('css selector', '#error > div.error_attrib > a').click()\n",
    "        \n",
    "                    \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tuplas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recogida de los datos\n",
    "for peli in info_por_peli:\n",
    "    \n",
    "    patron = re.compile(r'([a-z])([A-Z])')\n",
    "    patron_duracion = re.compile(r'\\b(?:\\d+h\\s*)?\\d+min\\b')\n",
    "    tupla_datos = [peli[0],] \n",
    "\n",
    "    # listas intermedias para ir checkeando\n",
    "    direccion = []\n",
    "    guion = []\n",
    "    nota = []\n",
    "    duracion = []\n",
    "    argumento = []\n",
    "        \n",
    "    for indice, linea in enumerate(peli[1]):\n",
    "               \n",
    "        \n",
    "        # directores    \n",
    "        if 'Dirección' in linea:\n",
    "                                \n",
    "            directores = patron.sub(r'\\1, \\2', peli[1][indice+1])\n",
    "            direccion.append(directores)            \n",
    "\n",
    "\n",
    "        # guionistas\n",
    "        elif 'Guión' in linea:\n",
    "            \n",
    "            guionistas = patron.sub(r'\\1, \\2', peli[1][indice+1])\n",
    "            guion.append(guionistas)\n",
    "                \n",
    "        \n",
    "        # nota y duracion\n",
    "        elif 'PUNTUACIÓN EN IMDb' in linea:\n",
    "            nota.append(float(peli[1][indice+1].replace(',', '.')))\n",
    "            \n",
    "            if r'\\d+h' or r'\\d+min' in peli[1][indice-1]:  \n",
    "                duracion.append(peli[1][indice-1])\n",
    "            \n",
    "                    \n",
    "        # argumento\n",
    "        elif 'Añade un argumento en tu idioma' in linea:\n",
    "            argumento.append(peli[1][indice+1])\n",
    "\n",
    "    # añadimos a la tupla los datos de la lista intermedia\n",
    "    for elemento in [direccion, guion, nota, duracion, argumento]:\n",
    "        if elemento != []:\n",
    "            tupla_datos.append(elemento[0])\n",
    "        else:\n",
    "            tupla_datos.append(np.nan)\n",
    "    \n",
    "    lista_tuplas.append(tupla_datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIMPIEZA DE LAS CLASIFICACIONES DE ROTTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpieza de las calificaciones de rotten de COMEDIA\n",
    "\n",
    "with open(\"Archivos_ROTTEM/rottem_comedia_sin_duplicados.csv\", 'r') as archivo:\n",
    "    leer = csv.reader(archivo)\n",
    "    lista = list(leer)\n",
    "\n",
    "lista_limpia_comedia = []\n",
    "lista_errores_comedia = []\n",
    "\n",
    "for sublista in lista:\n",
    "    if \"%\" not in sublista[1]:\n",
    "        lista_errores_comedia.append(sublista[0:2])\n",
    "        \n",
    "    else:\n",
    "        lista_limpia_comedia.append(sublista[0:2])        \n",
    "print(len(lista_limpia_comedia))\n",
    "print(len(lista_errores_comedia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_limpia_comedia[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpieza de las calificaciones de rotten de Accion\n",
    "\n",
    "with open(\"Archivos_ROTTEM/rottem_accion_completo_sin_duplicados.csv\", 'r') as archivo:\n",
    "    leer = csv.reader(archivo)\n",
    "    lista = list(leer)\n",
    "\n",
    "lista_limpia_accion = []\n",
    "lista_errores_accion = []\n",
    "\n",
    "for sublista in lista:\n",
    "    if \"%\" not in sublista[1]:\n",
    "        lista_errores_accion.append(sublista[0:2])\n",
    "        \n",
    "    else:\n",
    "        lista_limpia_accion.append(sublista[0:2])        \n",
    "print(len(lista_limpia_accion))\n",
    "print(len(lista_errores_accion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_limpia_accion[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpieza de las calificaciones de rotten de DRAMA\n",
    "\n",
    "with open(\"Archivos_ROTTEM/rottem_drama_sin_duplicados.csv\", 'r') as archivo:\n",
    "    leer = csv.reader(archivo)\n",
    "    lista = list(leer)\n",
    "\n",
    "lista_limpia_drama = []\n",
    "lista_errores_drama = []\n",
    "\n",
    "for sublista in lista:\n",
    "    if \"%\" not in sublista[1]:\n",
    "        lista_errores_drama.append(sublista[0:2])\n",
    "        \n",
    "    else:\n",
    "        lista_limpia_drama.append(sublista[0:2])        \n",
    "print(len(lista_limpia_drama))\n",
    "print(len(lista_errores_drama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar los tres documentos limpios como csv\n",
    "\n",
    "\n",
    "df_accion = pd.DataFrame(lista_limpia_accion)\n",
    "df_accion.to_csv(\"rottem_accion_completo_sin_duplicados_limpio.csv\", index=False)\n",
    "\n",
    "df_comedia = pd.DataFrame(lista_limpia_comedia)\n",
    "df_comedia.to_csv(\"rottem_comedia_sin_duplicados_limpio.csv\", index=False)\n",
    "\n",
    "df_drama = pd.DataFrame(lista_limpia_drama)\n",
    "df_drama.to_csv(\"rottem_drama_sin_duplicados_limpio.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
